\documentclass[12pt,a4paper]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\usepackage{lmodern}
\usepackage{graphicx}
\usepackage{minted}

\setlength{\parindent}{2em}
\setlength{\parskip}{1em}

\begin{document}

\title{Riconoscimento Documenti}
\author{Simone Cimarelli \and Vittorio Mignini \and Luca Moroni}
\date{9 luglio 2020}

\maketitle

\begin{abstract}
    Si descrive l'implementazione di una libreria basata su Mask-RCNN e
    tesseract per il riconoscimento interattivo di documenti
    identificativi e tessere.
\end{abstract}

\section{Obbiettivi}

Implementare tramite una libreria Python l'object detection all'interno
di immagini di una serie di tipologie di documenti estensibili dal
client, e il riconoscimento dei caratteri per classi di dati specifiche
per gli stessi.\\
Sarà fornito anche una possibile implementazione di un frontend basato
su tecnologie browser.

\section{Analisi dei Requisiti}
\subsection{Glossario}

\begin{description}
    \item[CNN] Convolutional Neural Network, rete neurale
        convoluzionale, adatta alla classificazione di intere immagini.

    \item[Mask-R\_CNN] region-based Convolutional Neural Network, libreria
        basata su Resnet 101 e tecnologia CNN in grado di effettuare
        segmentazione di immagini.

    \item[Segmentazione] Individuazione delle aree di un'immagine
        contenenti determinati oggetti.

    \item[Training] ``Allenamento'' della rete neurale al riconoscimento
        di uno o più tipi di documento.

    \item[Pesi] Valori calcolati nel processo di training che
        influenzano il comportamento della rete neurale, portandola a
        identificare le classi di oggetti desiderate.

    \item[OCR] Optical Character Recognition, riconoscimento ottico del
        testo di un documento.

    \item[ROI] Region Of Interest, regione di un immagine inferita dalla
        rete Mask-R\_CNN che con un alta probabilita contiene un oggetto
        identificato.

\end{description}

\subsection{Analisi Requisiti Utente}

\begin{itemize}
    \item Ottenere un elenco dei documenti visibili all'interno di
        un'immagine e le componenti testuali specifiche in esso
        riconoscibili.
    \item Avere la possibilità di definire la natura dei documenti
        oggetto del riconoscimento e delle informazioni testuali
        rilevanti in essi contenute.
    \item Fornire strumenti per il retraining della rete neurale per
        nuovi tipi di documento.
\end{itemize}

\subsection{Analisi Requisiti Sistema}

\begin{itemize}
    \item Target: Python 3.7, Tensorflow 1.13.1, Keras 2.0.8, ultime
        versioni certamente compatibili con la libreria Mask-R\_CNN
        utilizzata in questo progetto.
    \item Mettere a disposizione un'implementazione di riferimento di
        frontend compatibile con la libreria.
\end{itemize}

\section{Architettura del Sistema}

Il sistema è implementato in un modulo Python. Le funzionalità di
riconoscimento sono rese disponibili tramite istanza di una classe
\texttt{Detectron}, inizializzata tramite una struttura di
configurazione definibile dall'utente in congiunzione con i pesi della
rete neurale, per la massima estensibilità.

Una volta inizializzato, un oggetto \texttt{Detectron} offre un metodo
\texttt{recognize} che implementa la funzione di riconoscimento.\\
\texttt{recognize} accetta un oggetto \texttt{bytes}-like che
rappresenta l'immagine in un qualsiasi formato supportato dalla libreria
OpenCV2. Dopo aver decodificato l'immagine questa viene passata
attraverso la rete neurale Mask-R\_CNN precedentemente inizializzata, che
individua delle ROI associate ai tipi di documento configurati, a ognuna
delle quali sarà associato un dizionario. L'area di ogni ROI viene
estratta dall'immagine e memorizzata alla chiave ``\texttt{snapshot}'',
codificata in PNG in un oggetto \texttt{bytes}.

Su questi snapshot viene poi applicato l'algoritmo di OCR della libreria
tesseract. Quest'ultimo a sua volta restituirà una serie di record che
rappresentano il testo trovato, il grado confidenza e la relativa
posizione all'interno della ROI. Questi record sono identificati in base
alla posizione o al formato, specificato tramite regex. Il testo dei
record così individuati è aggiunto a un dizionario sotto il nome di
``\texttt{attributes}''. L'oggetto di configurazione definisce quali di
questi ``\texttt{attributes}'' sono necessari al riconoscimento del
documento e solo quando tutti questi sono effettivamente stati
individuati il documento viene marcato come valido. Uno degli attributi
necessari può essere designato come chiave primaria, quando un documento
è valido il valore della chiave primaria viene restituito nel dizionario
sotto il nome di ``\texttt{primaryKey}'' e può essere utilizzato per
l'identificazione univoca del documento appena scansionato. Si consiglia
di indicare come chiave primaria il codice o numero identificativo
univoco del documento, quando presente.\\
La funzione \texttt{recognize} ritorna in output una lista di questi
dizionari.

A titolo esemplificativo, si è progettato e realizzato un servizio web
che mette a disposizione una API REST, e una web app implementata in
HTML5, CSS3 e JavaScript, i quali espongono le funzionalità messe a
disposizione dalla suddetta libreria.

\pagebreak

\subsection{Esempio di configurazione}
\begin{minted}{python}
{
    "weights": "percorso/ai/pesi.h5",
    "classes": {
        "Tesserino": {
            "lang": "ita",
            "min_conf": 50,
            "primaryKey": "Matricola",
            "regions": [
                {
                    "name": "Matricola",
                    "type": "regex",
                    "rule": "^\\d{6}$",
                    "needed": True
                },
                {
                    "name": "Nome",
                    "type": "box",
                    "rule": [0, 0.6, 0.2, 1],
                    "needed": False
                }
            ]
        }
    }
}
\end{minted}

\begin{figure}[p]
  \caption{Diagramma delle Classi}
  \centering
  \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{uml_class.pdf}
\end{figure}

\begin{figure}[p]
  \caption{Diagramma di Stato}
  \centering
  \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{uml_state.pdf}
\end{figure}

\begin{figure}[p]
  \caption{Diagramma di Caso d'Uso}
  \centering
  \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{uml_use_case.pdf}
\end{figure}

\begin{figure}[p]
  \caption{Diagramma di Sequenza}
  \centering
  \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{uml_seq.pdf}
\end{figure}

\begin{figure}[p]
  \caption{Diagramma di Comunicazione}
  \centering
  \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{uml_comm.pdf}
\end{figure}

\begin{figure}[p]
  \caption{Diagramma di Attività}
  \centering
  \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{uml_activity.pdf}
\end{figure}

\pagebreak

\section{Design Pattern}

Un design pattern che in potenza poterebbe essere applicato è
decorator.\\
Inizialmente non eravamo convinti della thread safness
della funzione \texttt{recognize} nella classe \texttt{Detectron}. Una
possibile soluzione consisterebbe nel creare una classe
\texttt{DetectronPool}, la quale nell'inizializzazione carica una pool
di oggetti \texttt{Detectron}. Tale classe avrà un metodo
\texttt{recognize} che andrà a decorare l'omonimo metodo di
\texttt{Detectron}, il quale gestirebbe l'allocazione della risorsa al
thread chiamante in modo trasparente tramite un semaforo contatore
inizializzato al numero di \texttt{Detectron} nella pool, garantendo la
mutua esclusione nell'esecuzione del metodo \texttt{recognize} in
maniera totalmente trasparente per l'utilizzatore.

\end{document}
